<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Frank-Peter Schilling</title> <meta name="author" content="Frank-Peter Schilling"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://fpschill.github.io/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?2ed62375d27d1acd85fb25a8d933282f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <div class="navbar-brand social"> <a href="mailto:%73%63%69%6B@%7A%68%61%77.%63%68" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://orcid.org/0000-0002-7763-2140" title="ORCID" rel="external nofollow noopener" target="_blank"><i class="ai ai-orcid"></i></a> <a href="https://scholar.google.com/citations?user=ZgO3g3QAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/fpschill" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/frankpeterschilling" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://www.zhaw.ch/en/about-us/person/scik/" title="Work" rel="external nofollow noopener" target="_blank"><i class="fa-solid fa-briefcase"></i></a> </div> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/research/">research</a> </li> <li class="nav-item "> <a class="nav-link" href="/service/">service</a> </li> <li class="nav-item "> <a class="nav-link" href="/talks/">talks</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Frank-Peter</span> Schilling </h1> <p class="desc"></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/scik-480.webp 480w, /assets/img/scik-800.webp 800w, /assets/img/scik-1400.webp 1400w, " sizes="(min-width: 1024px) 298.2px, (min-width: 576px) 30vw, 95vw" type="image/webp"></source> <img src="/assets/img/scik.jpg?69011bffa7db2c7f6f74f715dc4e9cbc" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="scik.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="more-info"> <p>ZHAW School of Engineering</p> <p>Centre for AI (CAI)</p> <p>Office TN 03.64 </p> <p>Technikumstrasse 71</p> <p>CH-8401 Winterthur</p> </div> </div> <div class="clearfix"> <p>I am an associate professor (“Dozent”) and group leader at <a href="https://www.zhaw.ch/en/university/" rel="external nofollow noopener" target="_blank">Zuerich University of Applied Sciences ZHAW</a>, located in Winterthur, Switzerland. I am also adjunct professor for AI and Data Science with the <a href="https://www.wgtn.ac.nz/" rel="external nofollow noopener" target="_blank">Victoria University of Wellington</a>. I am deputy director of ZHAW’s <a href="https://www.zhaw.ch/en/engineering/institutes-centres/cai/" rel="external nofollow noopener" target="_blank">Centre for Artificial Intelligence CAI</a>, where I lead applied research projects in Artificial Intelligence and Deep Learning.</p> <p>My research focus is on Computer Vision with Deep Learning, building Machine Learning Systems (MLOps), Trustworhy AI and applications of Deep Learning in the Physical Sciences. I am head of continuing education at CAI, and I teach lectures and seminars at the BSc and MSc level in computer science and data science. I am the scientific coordinator of the <a href="https://phd-data-science.ch/" rel="external nofollow noopener" target="_blank">PhD programme in Data Science</a>, a collaboration between ZHAW and University of Zurich. Besides that, I am involved in ZHAW’s digitization initiative (“<a href="https://www.zhaw.ch/en/about-us/mission-and-strategy/strategic-initiative-zhaw-digital/" rel="external nofollow noopener" target="_blank">ZHAW digital</a>”) where I helped shaping the DIZH fellowship programme, and I organized the <a href="https://www.zhaw.ch/de/forschung/departementsuebergreifende-kooperationen/datalab/datalab-seminar/" rel="external nofollow noopener" target="_blank">ZHAW Datalab Seminar</a>.</p> <p>In a previous life, I performed fundamental research in Particle Physics at major international research Labs such as <a href="https://home.cern/" rel="external nofollow noopener" target="_blank">CERN</a> (Geneva) and <a href="http://www.desy.de/" rel="external nofollow noopener" target="_blank">DESY</a> (Hamburg). In 2012, I contributed to the experimental <a href="https://home.cern/science/physics/higgs-boson" rel="external nofollow noopener" target="_blank">discovery of the Higgs particle</a> at CERN, whose theoretical prediction (not our discovery, though) was awarded with the <a href="https://www.nobelprize.org/prizes/physics/2013/summary/" rel="external nofollow noopener" target="_blank">2013 Nobel Prize in Physics</a>. I obtained a PhD in physics from the University of Heidelberg in 2001.</p> <p><a href="https://www.zhaw.ch/en/about-us/person/scik/" rel="external nofollow noopener" target="_blank">Profile page at ZHAW</a></p> </div> <h2><a href="/news/" style="color: inherit;">news</a></h2> <div class="news"> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">May 31, 2024</th> <td> Our paper on AI certification <a class="citation" href="/publications#sds2024_cert">(Denzel et al., 2024)</a> won the best paper award at <a href="https://sds2024.ch/" rel="external nofollow noopener" target="_blank">SDS 2024</a>! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> </td> </tr> <tr> <th scope="row" style="width: 20%">Mar 12, 2024</th> <td> Three new conference papers in the context of certification of AI systems accepted: One at ESREL 2024 <a class="citation" href="/publications#esrel2024">(Billeter et al., 2024)</a>, and two at SDS 2024 <a class="citation" href="/publications#sds2024_cert">(Denzel et al., 2024)</a> <a class="citation" href="/publications#sds2024_mlops">(Billeter et al., 2024)</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Jan 27, 2024</th> <td> New website is up! </td> </tr> </table> </div> </div> <h2><a href="/publications/" style="color: inherit;">selected publications</a></h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">SDS 2024</abbr></div> <div id="sds2024_cert" class="col-sm-8"> <div class="title">Towards the Certification of AI-based Systems</div> <div class="author"> Philipp Denzel, Stefan Brunner, Yann Billeter, Oliver Forster, and <span class="more-authors" title="click to view 8 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '8 more authors' ? 'Carmen Frischknecht-Gruber, Monika Reif, Frank-Peter Schilling, Joanna Weng, Ricardo Chavarriaga, Amin Amini, Marco Repetto, Arman Iranfar' : '8 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, ''); ">8 more authors</span> </div> <div class="periodical"> <em>In SDS 2024: 11th IEEE Swiss Conference on Data Science</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="http://dx.doi.org/10.21256/zhaw-30439" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/bibliography/files/2024_Denzel-etal_Towards-the-Certification-of-AI-based-Systems_SDS24.pdf" class="btn btn-sm z-depth-0" role="button">File</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">SDS 2024</abbr></div> <div id="sds2024_mlops" class="col-sm-8"> <div class="title">MLOps as Enabler of Trustworthy AI</div> <div class="author"> Yann Billeter, Philipp Denzel, Ricardo Chavarriaga, Oliver Forster, and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Frank-Peter Schilling, Stefan Brunner, Carmen Frischknecht-Gruber, Monika Reif, Joanna Weng' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, ''); ">5 more authors</span> </div> <div class="periodical"> <em>In SDS 2024: 11th IEEE Swiss Conference on Data Science</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="http://dx.doi.org/10.21256/zhaw-30443" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/bibliography/files/2024_Billeter-etal_MLOps-for-Trustworthy-AI_SDS24.pdf" class="btn btn-sm z-depth-0" role="button">File</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">IEEE Access</abbr></div> <div id="amirian_2024" class="col-sm-8"> <div class="title">Artifact Reduction in 3D and 4D Cone-beam Computed Tomography Images with Deep Learning - A Review</div> <div class="author"> Mohammadreza Amirian, Daniel Barco, Ivo Herzig, and <em>Frank-Peter Schilling</em> </div> <div class="periodical"> <em>IEEE Access</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://dx.doi.org/10.1109/ACCESS.2024.3353195" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/bibliography/files/2024_Artifact_Reduction_in_3D_and_4D_Cone-beam_Computed_Tomography_Images_with_Deep_Learning_-_A_Review.pdf" class="btn btn-sm z-depth-0" role="button">File</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1109/ACCESS.2024.3353195" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Deep learning based approaches have been used to improve image quality in cone-beam computed tomography (CBCT), a medical imaging technique often used in applications such as image-guided radiation therapy, implant dentistry or orthopaedics. While deep learning methods have been applied to reduce various types of CBCT image artifacts arising from motion, metal objects, or low-dose acquisition, a comprehensive review summarizing the successes and shortcomings of these approaches, with a primary focus on the type of artifacts rather than the architecture of neural networks, is lacking in the literature. In this review, the data generation and simulation pipelines, as well as artifact reduction techniques are specifically investigated for each type of artifact. We provide an overview of deep learning techniques that have successfully been shown to reduce artifacts in 3D, as well as in time-resolved (4D) CBCT through the use of projection- and/or volume-domain optimizations, or by introducing neural networks directly within the CBCT reconstruction algorithms. Research gaps are identified to suggest avenues for future exploration. One of the key findings of this work is an observed trend towards the use of generative models including GANs and score-based or diffusion models, accompanied with the need for more diverse and open training datasets and simulations.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">amirian_2024</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Amirian, Mohammadreza and Barco, Daniel and Herzig, Ivo and Schilling, Frank-Peter}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Access}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Artifact Reduction in 3D and 4D Cone-beam Computed Tomography Images with Deep Learning - A Review}}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2169-3536}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{10281-10295}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{12}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ACCESS.2024.3353195}</span><span class="p">,</span>
  <span class="na">modificationdate</span> <span class="p">=</span> <span class="s">{2024-01-21T18:04:49}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Institute of Electrical and Electronics Engineers (IEEE)}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Med.Phys.</abbr></div> <div id="dir3ct" class="col-sm-8"> <div class="title">Mitigation of motion-induced artefacts in Cone Beam Computed Tomography using Deep Convolutional Neural Networks</div> <div class="author"> Mohammadreza Amirian, Javier A. Montoya-Zegarra, Ivo Herzig, Peter Eggenberger Hotz, and <span class="more-authors" title="click to view 9 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '9 more authors' ? 'Lukas Lichtensteiger, Marco Morf, Alexander Züst, Pascal Paysan, Igor Peterlik, Stefan Scheib, Rudolf Marcel Füchslin, Thilo Stadelmann, Frank-Peter Schilling' : '9 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, ''); ">9 more authors</span> </div> <div class="periodical"> <em>Med. Phys.</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://dx.doi.org/10.1002/mp.16405" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/bibliography/files/2023_Amirian_Mitigation_of_motion_induced_artifacts.pdf" class="btn btn-sm z-depth-0" role="button">File</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1002/mp.16405" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Background: Cone beam computed tomography (CBCT) is often employed on radiation therapy treatment devices (linear accelerators) used in image-guided radiation therapy (IGRT). For each treatment session, it is necessary to obtain the image of the day in order to accurately position the patient and to enable adaptive treatment capabilities including auto-segmentation and dose calculation. Reconstructed CBCT images often suffer from artifacts, in particular those induced by patient motion. Deep-learning based approaches promise ways to mitigate such artifacts. Purpose: We propose a novel deep-learning based approach with the goal to reduce motion induced artifacts in CBCT images and improve image quality. It is based on supervised learning and includes neural network architectures employed as pre- and/or post-processing steps during CBCT reconstruction. Methods: Our approach is based on deep convolutional neural networks which complement the standard CBCT reconstruction, which is performed either with the analytical Feldkamp-Davis-Kress (FDK) method, or with an iterative algebraic reconstruction technique (SART-TV). The neural networks, which are based on refined U-net architectures, are trained end-to-end in a supervised learning setup. Labeled training data are obtained by means of a motion simulation, which uses the two extreme phases of 4D CT scans, their deformation vector fields, as well as time-dependent amplitude signals as input. The trained networks are validated against ground truth using quantitative metrics, as well as by using real patient CBCT scans for a qualitative evaluation by clinical experts. Results: The presented novel approach is able to generalize to unseen data and yields significant reductions in motion induced artifacts as well as improvements in image quality compared with existing state-of-the-art CBCT reconstruction algorithms (up to +6.3 dB and +0.19 improvements in peak signal-to-noise ratio, PSNR, and structural similarity index measure, SSIM, respectively), as evidenced by validation with an unseen test dataset, and confirmed by a clinical evaluation on real patient scans (up to 74% preference for motion artifact reduction over standard reconstruction). Conclusions: For the first time, it is demonstrated, also by means of clinical evaluation, that inserting deep neural networks as pre- and post-processing plugins in the existing 3D CBCT reconstruction and trained end-to-end yield significant improvements in image quality and reduction of motion artifacts.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">dir3ct</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Amirian, Mohammadreza and Montoya-Zegarra, Javier A. and Herzig, Ivo and Hotz, Peter Eggenberger and Lichtensteiger, Lukas and Morf, Marco and Z\"ust, Alexander and Paysan, Pascal and Peterlik, Igor and Scheib, Stefan and F\"uchslin, Rudolf Marcel and Stadelmann, Thilo and Schilling, Frank-Peter}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Med. Phys.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Mitigation of motion-induced artefacts in Cone Beam Computed Tomography using Deep Convolutional Neural Networks}}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{10}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{6228-6242}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{50}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1002/mp.16405}</span><span class="p">,</span>
  <span class="na">modificationdate</span> <span class="p">=</span> <span class="s">{2024-02-03T16:37:27}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%73%63%69%6B@%7A%68%61%77.%63%68" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://orcid.org/0000-0002-7763-2140" title="ORCID" rel="external nofollow noopener" target="_blank"><i class="ai ai-orcid"></i></a> <a href="https://scholar.google.com/citations?user=ZgO3g3QAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/fpschill" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/frankpeterschilling" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://www.zhaw.ch/en/about-us/person/scik/" title="Work" rel="external nofollow noopener" target="_blank"><i class="fa-solid fa-briefcase"></i></a> </div> <div class="contact-note"> </div> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Frank-Peter Schilling. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: September 23, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?9b43d6e67ddc7c0855b1478ee4c48c2d" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>