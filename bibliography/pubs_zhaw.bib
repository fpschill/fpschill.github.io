% Encoding: ISO-8859-1

@Article{Amirian_2024,
  author           = {Amirian, Mohammadreza and Barco, Daniel and Herzig, Ivo and Schilling, Frank-Peter},
  journal          = {IEEE Access},
  title            = {{Artifact Reduction in 3D and 4D Cone-beam Computed Tomography Images with Deep Learning - A Review}},
  year             = {2024},
  volume =        {12},
  pages = {10281-10295},
  issn             = {2169-3536},
  doi              = {10.1109/ACCESS.2024.3353195},
  file             = {:files/Artifact_Reduction_in_3D_and_4D_Cone-beam_Computed_Tomography_Images_with_Deep_Learning_-_A_Review.pdf:PDF},
  modificationdate = {2024-01-21T18:04:49},
  publisher        = {Institute of Electrical and Electronics Engineers (IEEE)},
  abstract = {Deep learning based approaches have been used to improve image quality in cone-beam computed tomography (CBCT), a medical imaging technique often used in applications such as image-guided radiation therapy, implant dentistry or orthopaedics. While deep learning methods have been applied to reduce various types of CBCT image artifacts arising from motion, metal objects, or low-dose acquisition, a comprehensive review summarizing the successes and shortcomings of these approaches, with a primary focus on the type of artifacts rather than the architecture of neural networks, is lacking in the literature. In this review, the data generation and simulation pipelines, as well as artifact reduction techniques are specifically investigated for each type of artifact. We provide an overview of deep learning techniques that have successfully been shown to reduce artifacts in 3D, as well as in time-resolved (4D) CBCT through the use of projection- and/or volume-domain optimizations, or by introducing neural networks directly within the CBCT reconstruction algorithms. Research gaps are identified to suggest avenues for future exploration. One of the key findings of this work is an observed trend towards the use of generative models including GANs and score-based or diffusion models, accompanied with the need for more diverse and open training datasets and simulations.},
  selected={true},
  abbr={IEEE Access},
  bibtex_show={true},
  dimensions={true},
}

@Conference{xaimed2023,
author    = {Denzel, Philipp and Brunner, Stefan and Luley, Paul-Philipp and Frischknecht-Gruber, Carmen and Reif, Monika Ulrike and Schilling, Frank-Peter and Amini, Amin and Repetto, Marco and Iranfar, Arman and Weng, Joanna and Chavarriaga, Ricardo},
  booktitle = {Explainable AI in Medicine Workshop, Lugano, Switzerland, November 2023},
  title     = {{A framework for assessing and certifying explainability of health-oriented AI systems}},
  year      = {2023},
  url       = {https://digitalcollection.zhaw.ch/handle/11475/29258},
}

@InProceedings{hammers2023,
  author           = {Denzel, Philipp and Schilling, Frank-Peter and Gavagnin, Elena},
  booktitle        = {Hammers \& Nails 2023 - Swiss Edition, Ascona, Switzerland, October 2023},
  title            = {{Map-to-map translation for SKA mock observations and cosmological simulations}},
  year             = {2023},
  doi              = {10.21256/zhaw-29047},
  file             = {:files/2023_Denzel-Schilling-Gavagnin_H&N-Poster.pdf:PDF},
  modificationdate = {2024-01-21T18:01:41},
}

@Article{dir3ct,
  author           = {Mohammadreza Amirian and Javier A. Montoya-Zegarra and Ivo Herzig and Peter Eggenberger Hotz and Lukas Lichtensteiger and Marco Morf and Alexander Z\"ust and Pascal Paysan and Igor Peterlik and Stefan Scheib and Rudolf Marcel F\"uchslin and Thilo Stadelmann and Frank-Peter Schilling},
  journal          = {Med. Phys.},
  title            = {{Mitigation of motion-induced artefacts in Cone Beam Computed Tomography using Deep Convolutional Neural Networks}},
  year             = {2023},
  number           = {10},
  pages            = {6228-6242},
  volume           = {50},
  doi              = {10.1002/mp.16405},
  file             = {:files/Medical Physics - 2023 - Amirian - Mitigation of motion?induced artifacts in cone beam computed tomography using deep.pdf:PDF},
  modificationdate = {2024-01-21T18:00:39},
  dimensions={true},
  abbr={Med.Phys.},
  bibtex_show={true},
  abstract={
Background: Cone beam computed tomography (CBCT) is often employed on radiation therapy treatment devices (linear accelerators) used in image-guided radiation therapy (IGRT). For each treatment session, it is necessary to obtain the image of the day in order to accurately position the patient and to enable adaptive treatment capabilities including auto-segmentation and dose calculation. Reconstructed CBCT images often suffer from artifacts, in particular those induced by patient motion. Deep-learning based approaches promise ways to mitigate such artifacts.
Purpose: We propose a novel deep-learning based approach with the goal to reduce motion induced artifacts in CBCT images and improve image quality. It is based on supervised learning and includes neural network architectures employed as pre- and/or post-processing steps during CBCT reconstruction.
Methods: Our approach is based on deep convolutional neural networks which complement the standard CBCT reconstruction, which is performed either with the analytical Feldkamp-Davis-Kress (FDK) method, or with an iterative algebraic reconstruction technique (SART-TV). The neural networks, which are based on refined U-net architectures, are trained end-to-end in a supervised learning setup. Labeled training data are obtained by means of a motion simulation, which uses the two extreme phases of 4D CT scans, their deformation vector fields, as well as time-dependent amplitude signals as input. The trained networks are validated against ground truth using quantitative metrics, as well as by using real patient CBCT scans for a qualitative evaluation by clinical experts.
Results: The presented novel approach is able to generalize to unseen data and yields significant reductions in motion induced artifacts as well as improvements in image quality compared with existing state-of-the-art CBCT reconstruction algorithms (up to +6.3 dB and +0.19 improvements in peak signal-to-noise ratio, PSNR, and structural similarity index measure, SSIM, respectively), as evidenced by validation with an unseen test dataset, and confirmed by a clinical evaluation on real patient scans (up to 74% preference for motion artifact reduction over standard reconstruction).
Conclusions: For the first time, it is demonstrated, also by means of clinical evaluation, that inserting deep neural networks as pre- and post-processing plugins in the existing 3D CBCT reconstruction and trained end-to-end yield significant improvements in image quality and reduction of motion artifacts.
},
}

@InProceedings{certaintyposter2023,
  author           = {Weng, Joanna and Reif, Monika and Chavarriaga, Ricardo and Schilling, Frank-Peter},
  booktitle        = {Poster presented at ZHAW Datalab Symposium, Winterthur, Switzerland},
  title            = {{certAInty: a certification scheme for AI systems}},
  year             = {2023},
  doi              = {10.21256/zhaw-27261},
  file             = {:files/2023_Weng-etal_certAInty-Poster_Datalab23.pdf:PDF},
  modificationdate = {2023-03-13T08:10:46},
}

@InProceedings{skaposter2023,
  author           = {Denzel, Philipp and Gavagnin, Elena and Schilling, Frank-Peter},
  booktitle        = {Poster presented at ZHAW Datalab Symposium, Winterthur, Switzerland},
  title            = {{Deep learning the SKA: the Square Kilometer Array project}},
  year             = {2023},
  doi              = {10.21256/zhaw-27219},
  file             = {:files/2023_Denzel-etal_Deep-learning-the-SKA_ZHAW-Poster.pdf:PDF},
  modificationdate = {2023-03-08T08:47:17},
}

@Article{ISSDS21,
  author  = {Schilling, Frank-Peter AND Flumini, Dandolo AND F{\"u}chslin, Rudolf M. AND Gavagnin, Elena AND Geller, Armando AND Quarteroni, Silvia AND Stadelmann, Thilo},
  title   = {{Foundations of Data Science: A Comprehensive Overview Formed at the 1st International Symposium on the Science of Data Science}},
  journal = {Archives of Data Science, Series A},
  year    = {2022},
  volume  = {8},
  number  = {2},
  pages   = {1 -- 20},
  doi     = {10.5445/IR/1000146422},
  file    = {:files/AoDSA_2022b.pdf:PDF},
  dimensions={true},
  abbr={AoDS},
  bibtex_show={true},
}

@InProceedings{aapm2022,
  author           = {Herzig, Ivo and Paysan, Pascal and Scheib, Stefan and Schilling, Frank-Peter and Montoya, Javier and Amirian, Mohammadreza and Stadelmann, Thilo and Eggenberger, Peter and F{\"u}chslin, Rudolf M. and Lichtensteiger, Lukas},
  booktitle        = {Proceedings of the American Association of Physics in Medicine Annual Meeting (AAPM 2022)},
  title            = {{Deep Learning-Based Simultaneous Multi-Phase Deformable Image Registration of Sparse 4D-CBCT}},
  year             = {2022},
  note             = {{Washington, DC, USA, July 2022}},
  doi              = {10.21256/zhaw-25181},
  modificationdate = {2023-03-08T08:48:49},
}

@Book{mdpi2022,
  title     = {{Advances in Deep Neural Networks for Visual Pattern Recognition}},
  publisher = {MDPI},
  year      = {2022},
  editor    = {Stadelmann, Thilo and Schilling, Frank-Peter},
  note    = {{Special issue of J. Imaging (ISSN 2313-433X)}},
  url={https://www.mdpi.com/journal/jimaging/special_issues/deep_neural_network},
}


@INPROCEEDINGS{sds2021,
	author={Simmler, Niclas and Sager, Pascal and Andermatt, Philipp and Chavarriaga, Ricardo and Schilling, Frank-Peter and Rosenthal, Matthias and Stadelmann, Thilo},
	booktitle={8th Swiss Conference on Data Science (SDS)}, 
	title={A Survey of Un-, Weakly-, and Semi-Supervised Learning Methods for Noisy, Missing and Partial Labels in Industrial Vision Applications}, 
	year={2021},
	volume={},
	number={},
	pages={26-31},
	doi={10.1109/SDS51136.2021.00012},
	file    = {:files/sds2021.pdf:PDF},
    dimensions={true},
    abbr={IEEE},
    bibtex_show={true},
}


@Book{mdpi2020,
  title     = {{Artificial Neural Networks in Pattern Recognition}},
  publisher = {MDPI},
  year      = {2020},
  editor    = {Schilling, Frank-Peter and Stadelmann, Thilo},
  note    = {{Special issue of Computers (ISSN 2073-431X)}},
  url={https://www.mdpi.com/journal/computers/special_issues/ANNPR2020},
}

@Article{autodl,
  author  = {Tuggener, Lukas and Amirian, Mohammadreza and Benites, Fernando and von D{\"a}niken, Pius and Gupta, Prakhar and Schilling, Frank-Peter and Stadelmann, Thilo},
  title   = {{Design Patterns for Resource-Constrained Automated Deep-Learning Methods}},
  journal = {AI},
  year    = {2020},
  volume  = {1},
  number  = {4},
  pages   = {510--538},
  doi     = {10.3390/ai1040031},
  file    = {:files/ai2020.pdf:PDF},
  dimensions={true},
  abbr={MDPI AI},
  bibtex_show={true},
}

@proceedings{annpr2020proc,
  title     = {{Artificial neural networks in pattern recognition : Proceedings of the 9th IAPR TC3 workshop, ANNPR 2020, Winterthur, Switzerland, September 2-4, 2020}},
  year      = {2020},
  editor    = {Schilling, Frank-Peter and Stadelmann, Thilo},
  volume    = {Lecture Notes in Computer Science},
  number    = {12294},
  publisher = {Springer},
  doi       = {10.1007/978-3-030-58309-5},
  abbr={Springer},
  dimensions={true},
  bibtex_show={true},
}

@Article{Amirian2020,
  author  = {Amirian, Mohammadreza and Tuggener, Lukas and Chavarriaga, Ricardo and Satyawan, Yvan Putra and Schilling, Frank-Peter and Schwenker, Friedhelm and Stadelmann, Thilo},
  title   = {Two to trust: AutoML for safe modelling and interpretable deep learning for robustness},
  journal = {Proc. of the 1st TAILOR Workshop on Trustworthy AI at ECAI 2020},
  year    = {2020},
  file    = {:files/Amirian2020.pdf:PDF},
  doi={10.21256/zhaw-22061},
}

@Article{Amirian2019a,
  author    = {Amirian, Mohammadreza and Rombach, Katharina and Tuggener, Lukas and Schilling, Frank-Peter and Stadelmann, Thilo},
  title     = {Efficient deep CNNs for cross-modal automated computer vision under time and space constraints},
  journal = {Proc. of ECML-PKDD 2019, W\"urzburg},
  year      = {2019},
  file      = {:files/Amirian2019a.pdf:PDF},
  doi = {10.21256/zhaw-18357},
}

@Article{itforhealth2019,
  author  = {Schilling, Frank-Peter and Stadelmann, Thilo},
  title   = {{Deep Learning in medizinischer Diagnostik und Qualit\"ats-kontrolle}},
  journal = {Netzwoche, Special Issue: IT for Health},
  year    = {2019},
  doi     = {10.21256/zhaw-20163},
  file    = {:files/itforhealth2019.pdf:PDF},
}

@Comment{jabref-meta: databaseType:bibtex;}
